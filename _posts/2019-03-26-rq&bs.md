---
layout: post
title: Requests & BeautifulSoup 笔记
date: 2019-03-26
catalog: true
header-img: img/programming.jpg
tags:
    - Python
---

## Requests
#### snippets
```python
import requests
html = requests.get(url, headers=headers, cookies=cookies, timeout=seconds)
# 该方法返回的Response对象常用的两个属性
statusCode = html.status_code
html_text = html.text
```

#### 一些经验
大部分网站会采取一些反爬措施，常见的有：封锁ip，后台验证cookies。访问某些资源时需要从浏览器的调试器中获取登录后的cookies，该cookies多次爬取后可能会失效。前者可以搭建ip代理池；后者可以使用Session模拟登陆，有验证码的情况下手动处理可能还方便一些。

#### Session会话
会话可以跨请求保持某些参数，一个session的所有请求都会保持一样的cookie，通过这个就可以模拟登录、爬取登录后才能获取的网页或者数据库信息。

#### 使用headers和Cookie
都是接受一个字典，在headers中也可以设置cookies。一般来讲，大部分网站不会对headers进行拦截。Cookie经常用来携带登录信息。

#### 使用代理
在requests.get方法中设置proxies参数，接受一个字典。该字典有可设置两个key: 'http' and 'https', 来分别处理两种协议的网址，所以应当注意当前爬取网址采用的是哪种协议。value的取值是http://ip:port。eg. 
```
proxies = {
  "http": "http://10.10.1.10:3128",
  "https": "http://10.10.1.10:1080",
}
```

#### 设置timeout是一个好习惯
官方文档建议这个数字稍微比3的倍数大一点，因为 TCP 数据包重传窗口 (TCP packet retransmission window) 的默认大小是 3。

## BeautifulSoup
#### snippets
```python
from bs4 import BeautifulSoup
import requests
html_doc = requests.get(url).text
soup = BeautifulSoup(html_doc, 'lxml')
# then find_all and other methods and attrs are available.
```

#### soup 对象
soup.[tagName]可以直接访问该soup中第一个匹配该tagName的标签。

常用的是soup.title获得该网页的标题，以及一些其他网页唯一标签。

#### 获取标签内的字符串
1. tag.string, 返回一个NavigableString（bs4对python原生str的包装），适用于：该tag内只有一个字符串
2. tag.strings, 返回的是一个迭代器，适用于该标签内有多个子标签
3. tag.get_text(), 返回该tag内所有的字符串的联合整体。该方法的具体参数可见help， 常用的参数是strip=True，去掉空格、缩进、转行等空白。

#### 获取标签的属性值
tag['class'], tag['id'] etc.

#### 搜索标签
##### find_all( name , attrs , recursive , string , \**kwargs )
注意事项：

1. 返回的是一个列表，**调用该方法可以简写为tag(), 即tag.find_all('a') 等价于 tag('a')**
2. name, attrs中的value, string的值是过滤器，可以是字符串，True（表示含有），正则表达式，甚至方法
3. name表示标签名
4. attrs接收的是一个字典，用于包含特殊属性，例如data-\*属性。
5. recessive：True or False，是否遍历所有子孙节点，还是只遍历直接子节点
6. kwargs：如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索,如果包含一个名字为 id 的参数,Beautiful Soup会搜索每个tag的”id”属性.

一些例子：
1. tag('div', 'content'), 匹配所有class为content的div标签，这里比较奇怪，'content'作为attrs参数传入被解读为class_='content'，而文档中attrs接收的是一个字典，用于包含特殊属性，例如data-\*属性。
2. tag('div', id=True), 匹配所有含有id属性的div标签。

##### find
参数于find_all相同， 返回第一个匹配的tag

#### select
**css选择器！！** 如果写过一点前端，用这个方法很顺手，比较适合从嵌套的html层级中选择标签。例如: `soup.select('div.content>p#title')`, 返回匹配class为content的div层的p子标签，其id是title。