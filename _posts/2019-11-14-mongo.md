---
layout: post
title: Spark连接MongoDB
date: 2019-11-14
catalog: true
header-img: img/programming.jpg
tags:
    - python
    - spark
    - mongodb
---
### 1 安装 MongoDB
#### 1.1 下载安装 MongoDB(Community Server)
选择社区版本，开源、免费，面向个人用户。
![-20191114-11-42-29.png](https://blog-data.oss-cn-beijing.aliyuncs.com/img/-20191114-11-42-29.png)

下载完成后解压，为了简洁，重命名为`mongodb`。里面主要包含了`bin`文件夹，我们接下来要用的MongoDB相关的二进制文件都在`bin`文件夹。

<img src="https://blog-data.oss-cn-beijing.aliyuncs.com/img/-20191114-15-56-03.png" width="300" align=center />

将`mongodb`文件夹放到合适的位置，然后将`mongodb/bin`添加到环境变量中：
```sh
# 向shell的配置文件例如：~/.bashrc，~/.zshrc 追加下面这行
# 注意根据你的目录结构修改path/to/mongodb/bin
export PATH=path/to/mongodb/bin:$PATH
```
检查是否安装好mongodb，有类似的输出就说明成功安装:
```sh
# 终端输入
> db version v4.2.1
git version: edf6d45851c0b9ee15548f0f847df141764a317e
allocator: system
modules: none
build environment:
    distarch: x86_64
    target_arch: x86_64
```

#### 1.2 启动 MongoDB 服务器
首先需要创建`mongodb`的数据存储位置，默认的位置是`/data/db`，我们可以自定义创建一个文件夹，例如`/Users/zeason/usr/mongo-data`。

在终端启动`mongodb`的服务器端，命令是`mongod`，然后指定我们刚刚自定义创建的数据存储路径：`mongod --dbpath=/Users/zeason/usr/mongo-data`

#### 1.3 连接并创建数据库和集合
`Mongodb`作为NOSQL数据库，在概念和操作方面和关系型数据库有着很多不同，具体可以参考网上教程。

在终端输入连接数据库的命令`mongo`，默认进入`test`数据库，我们新建一个集合并插入一些数据，准备给spark读写。
```sh
> db.student.insertMany([{"name":"彭子健", "age": 22}, {"name": "师兵范", "age": 22}])
```
我们在test数据库中创建了一个`student`表，并插入了两条数据。

### 2 安装 pyspark
spark是用Scala编写的，而Scala用到的运行时是Java虚拟机，所以要运行spark必须要在本地安装好Java，可参考网上教程，重点是设置好环境变量`$JAVA_HOME`。

在本地安装Spark有两种方式：（1）官网下载完整版本；（2）pyspark。这里我们使用第二种方法安装。可以使用pip：`pip3 install pyspark`，安装包文件很大，请切换到国内Pypi镜像（如清华镜像）；或者直接从镜像网站上下载解压然后安装。本文的版本是2.4.4。

<img src="https://blog-data.oss-cn-beijing.aliyuncs.com/img/-20191114-17-01-51.png" width="300" align=center />


安装好后还需要设置spark后台运行时使用的python版本，需与前台使用的版本一致:
```sh
# 向shell的配置文件例如：~/.bashrc，~/.zshrc 追加下面这行
# 注意根据你的目录结构修改python路径
export PYSPARK_PYTHON=path/to/python
```

### 3 Spark 连接到 MongoDB
首先我们要启动MongoDB服务，并且做好了测试数据，参照上文。我们介绍两种方法：shell，jupyter，来连接MongoDB，从而进行读写操作。

#### 3.1 pyspark shell
我们可以开启一个pyspark命令行环境：
```
> pyspark --conf "spark.mongodb.input.uri=mongodb://127.0.0.1/test.student?readPreference=primaryPreferred" \
    --conf "spark.mongodb.output.uri=mongodb://127.0.0.1/test.student" \
    --packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.1
```
上面的命令指定了三个参数：
1. `spark.mongodb.input.uri`：读取mongoddb的位置，我们设置为test数据库的student集合
2. `spark.mongodb.output.uri`: 写入mongoddb的位置，也设置为test数据库的student集合
3. `packages`：spark连接mongodb数据库所需要的jar包,

数据库读写的位置也可以通过spark提供的api修改。

#### 3.2 jupyter notebook
上面这这种方式会自动的创建一个名为`spark`的`SparkSession`对象，而在jupyter或者python脚本中，就需要手动的通过`SparkSession.builder`创建一个自定义的`SparkSession`对象：
```python
from pyspark.sql import SparkSession

spark = SparkSession \
    .builder \
    .appName("myApp") \
    .config("spark.mongodb.input.uri", "mongodb://127.0.0.1/test.coll") \
    .config("spark.mongodb.output.uri", "mongodb://127.0.0.1/test.coll") \
    .getOrCreate()
```
### 4 数据库操作
#### 4.1 读取数据
读取整个集合，默认读取的集合是启动shell或者创建`SparkSession`对象所设置的集合：
```python
df = spark.read.format("mongo").load()
df.show()
```
![-20191114-22-24-02.png](https://blog-data.oss-cn-beijing.aliyuncs.com/img/-20191114-22-24-02.png)

也可以读取其他库的其他集合：
```python
df = spark.read.format("mongo").option("uri",
"mongodb://127.0.0.1/people.contacts").load()
```
#### 4.2 插入数据
有时我们想把spark中的DataFrame插入到MongoDB中的集合中。下面我们创建一个DataFrame，然后写入到`test.student`这个集合当中去。
```python
other_students= spark.createDataFrame([('小明', 9), ('Alice', 19)],['name','age'])
other_students.write.format("mongo").mode("append").save()
df.show()
```
![-20191114-22-38-03.png](https://blog-data.oss-cn-beijing.aliyuncs.com/img/-20191114-22-38-03.png)

#### 4.3 Filter和SQL
Filter是spark中DataFrame的一个方法，可以获取集合中符合条件的部分文档。还是我们刚刚的例子，现在我们把年龄大于20岁的同学过滤出来：
```python
df.filter(df['age'] >= 20).show()
```
![-20191114-22-44-15.png](https://blog-data.oss-cn-beijing.aliyuncs.com/img/-20191114-22-44-15.png)


我们也可以通过SQL语句来获得满足查询条件的文档，在进行SQL查询前，需要注册一个临时视图，将其取名为`temp`：
```python
df.createOrReplaceTempView("temp")
some_student= spark.sql("SELECT type, qty FROM temp WHERE name LIKE '%A%'")
some_student.show()
```
![-20191114-22-50-33.png](https://blog-data.oss-cn-beijing.aliyuncs.com/img/-20191114-22-50-33.png)
